{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sentiment analysis, a common Natural Language Processing method, was applied to big data of Amazon reviews. \n",
    "It will process the large-scale datasets using Apache Spark's RDD to partition and distribute.\n",
    "The pre-processing on the big data will be done using PySpark, and the in-depth processing will be done in Python.\n",
    "Like real world situations, we will take the best of both worlds.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading to train and test RDDs, creating union of train and test\n",
    "train = sc.textFile(\"/FileStore/tables/train_ft-bfd00.txt\", 2) \n",
    "test = sc.textFile(\"/FileStore/tables/test_ft-41af5.txt\", 2)\n",
    "df = train.union(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">3</span><span class=\"ansired\">]: </span>\n",
       "[&apos;__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^&apos;,\n",
       " &quot;__label__2 The best soundtrack ever to anything.: I&apos;m reading a lot of reviews saying that this is the best &apos;game soundtrack&apos; and I figured that I&apos;d write a review to disagree a bit. This in my opinino is Yasunori Mitsuda&apos;s ultimate masterpiece. The music is timeless and I&apos;m been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.&quot;]\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first 2 train set rows\n",
    "train.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">21</span><span class=\"ansired\">]: </span>\n",
       "[&apos;__label__2 Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\&apos;m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\&apos;s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing &quot;Who was that singing ?&quot;&apos;,\n",
       " &quot;__label__2 One of the best game music soundtracks - for a game I didn&apos;t really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there&apos;s not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren&apos;t included I would still consider the collection worth it.&quot;]\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first 2 test set rows\n",
    "test.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "remove \\\n",
    "('__level__1 or __level__2  review title : review sentences'  ,  'train1' or 'test1'\n",
    "1 indicates bad, 2 indicates good\n",
    "CAPS for emphasizing\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Size of dataset:  4000000\n",
       "Split done! Time elapsed: 23.306551933288574 seconds\n",
       "<span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>\n",
       "[[&apos;2&apos;,\n",
       "  &apos;Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^&apos;],\n",
       " [&apos;2&apos;,\n",
       "  &quot;The best soundtrack ever to anything.: I&apos;m reading a lot of reviews saying that this is the best &apos;game soundtrack&apos; and I figured that I&apos;d write a review to disagree a bit. This in my opinino is Yasunori Mitsuda&apos;s ultimate masterpiece. The music is timeless and I&apos;m been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.&quot;]]\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "# cleaning to get label numbers and reviews \n",
    "df = df.map(lambda x: x.split('__label__')[1].split(\" \", 1))\n",
    "print(\"Size of dataset: \", df.count())\n",
    "# counting the time\n",
    "print('Split done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-----+--------------------+\n",
       "Label|              Review|\n",
       "+-----+--------------------+\n",
       "    2|Stuning even for ...|\n",
       "    2|The best soundtra...|\n",
       "+-----+--------------------+\n",
       "only showing top 2 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert PipelineRDD to DataFrame\n",
    "df1 = df.toDF([\"Label\",\"Review\"])\n",
    "df1.describe()\n",
    "df1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>pyspark.sql.dataframe.DataFrame\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansired\">ValueError</span>                                Traceback (most recent call last)\n",
       "<span class=\"ansigreen\">&lt;command-1532425816074300&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n",
       "<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># label 2 = good , label 1 = bad</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span><span class=\"ansigreen\">if</span> df1<span class=\"ansiyellow\">[</span><span class=\"ansiblue\">&quot;Label&quot;</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">==</span><span class=\"ansiblue\">&quot;2&quot;</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">      3</span>   df1<span class=\"ansiyellow\">[</span><span class=\"ansiblue\">&quot;Label&quot;</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">.</span>replace<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;2&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;good&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">      4</span> <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">      5</span>   df1<span class=\"ansiyellow\">[</span><span class=\"ansiblue\">&quot;Label&quot;</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">.</span>replace<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;1&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;bad&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/column.py</span> in <span class=\"ansicyan\">__nonzero__</span><span class=\"ansiblue\">(self)</span>\n",
       "<span class=\"ansigreen\">    680</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    681</span>     <span class=\"ansigreen\">def</span> __nonzero__<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 682</span><span class=\"ansiyellow\">         raise ValueError(&quot;Cannot convert column into bool: please use &apos;&amp;&apos; for &apos;and&apos;, &apos;|&apos; for &apos;or&apos;, &quot;\n",
       "</span><span class=\"ansigreen\">    683</span>                          &quot;&apos;~&apos; for &apos;not&apos; when building DataFrame boolean expressions.&quot;)\n",
       "<span class=\"ansigreen\">    684</span>     __bool__ <span class=\"ansiyellow\">=</span> __nonzero__<span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansired\">ValueError</span>: Cannot convert column into bool: please use &apos;&amp;&apos; for &apos;and&apos;, &apos;|&apos; for &apos;or&apos;, &apos;~&apos; for &apos;not&apos; when building DataFrame boolean expressions.</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label 2 = good , label 1 = bad\n",
    "if df1[\"Label\"]==\"2\":\n",
    "  df1[\"Label\"].replace(\"2\", \"good\")\n",
    "else:\n",
    "  df1[\"Label\"].replace(\"1\", \"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "new_df = df1.withColumn('Label', lit(\"good\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansired\">ValueError</span>                                Traceback (most recent call last)\n",
       "<span class=\"ansigreen\">&lt;command-1532425816074299&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n",
       "<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>sentiment<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">&quot;good&quot;</span> <span class=\"ansigreen\">if</span><span class=\"ansiyellow\">(</span>df1<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">==</span><span class=\"ansiblue\">&quot;2&quot;</span><span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">else</span> <span class=\"ansiblue\">&quot;bad&quot;</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">      2</span> sentence<span class=\"ansiyellow\">=</span>temp<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">:</span>len<span class=\"ansiyellow\">(</span>temp<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/column.py</span> in <span class=\"ansicyan\">__nonzero__</span><span class=\"ansiblue\">(self)</span>\n",
       "<span class=\"ansigreen\">    680</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    681</span>     <span class=\"ansigreen\">def</span> __nonzero__<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 682</span><span class=\"ansiyellow\">         raise ValueError(&quot;Cannot convert column into bool: please use &apos;&amp;&apos; for &apos;and&apos;, &apos;|&apos; for &apos;or&apos;, &quot;\n",
       "</span><span class=\"ansigreen\">    683</span>                          &quot;&apos;~&apos; for &apos;not&apos; when building DataFrame boolean expressions.&quot;)\n",
       "<span class=\"ansigreen\">    684</span>     __bool__ <span class=\"ansiyellow\">=</span> __nonzero__<span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansired\">ValueError</span>: Cannot convert column into bool: please use &apos;&amp;&apos; for &apos;and&apos;, &apos;|&apos; for &apos;or&apos;, &apos;~&apos; for &apos;not&apos; when building DataFrame boolean expressions.</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment=\"good\" if(df1[0]==\"2\") else \"bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n",
       "<span class=\"ansigreen\">&lt;command-1742976175039855&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n",
       "<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># compare the 2 labels</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">      2</span> <span class=\"ansigreen\">import</span> seaborn <span class=\"ansigreen\">as</span> sns<span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>sns<span class=\"ansiyellow\">.</span>countplot<span class=\"ansiyellow\">(</span>df1<span class=\"ansiyellow\">[</span><span class=\"ansiblue\">&apos;Label&apos;</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/seaborn/categorical.py</span> in <span class=\"ansicyan\">countplot</span><span class=\"ansiblue\">(x, y, hue, data, order, hue_order, orient, color, palette, saturation, ax, **kwargs)</span>\n",
       "<span class=\"ansigreen\">   3256</span>                           estimator<span class=\"ansiyellow\">,</span> ci<span class=\"ansiyellow\">,</span> n_boot<span class=\"ansiyellow\">,</span> units<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">   3257</span>                           orient<span class=\"ansiyellow\">,</span> color<span class=\"ansiyellow\">,</span> palette<span class=\"ansiyellow\">,</span> saturation<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">-&gt; 3258</span><span class=\"ansiyellow\">                           errcolor)\n",
       "</span><span class=\"ansigreen\">   3259</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">   3260</span>     plotter<span class=\"ansiyellow\">.</span>value_label <span class=\"ansiyellow\">=</span> <span class=\"ansiblue\">&quot;count&quot;</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/seaborn/categorical.py</span> in <span class=\"ansicyan\">__init__</span><span class=\"ansiblue\">(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, orient, color, palette, saturation, errcolor, errwidth, capsize)</span>\n",
       "<span class=\"ansigreen\">   1541</span>         <span class=\"ansiblue\">&quot;&quot;&quot;Initialize the plotter.&quot;&quot;&quot;</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">   1542</span>         self.establish_variables(x, y, hue, data, orient,\n",
       "<span class=\"ansigreen\">-&gt; 1543</span><span class=\"ansiyellow\">                                  order, hue_order, units)\n",
       "</span><span class=\"ansigreen\">   1544</span>         self<span class=\"ansiyellow\">.</span>establish_colors<span class=\"ansiyellow\">(</span>color<span class=\"ansiyellow\">,</span> palette<span class=\"ansiyellow\">,</span> saturation<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">   1545</span>         self<span class=\"ansiyellow\">.</span>estimate_statistic<span class=\"ansiyellow\">(</span>estimator<span class=\"ansiyellow\">,</span> ci<span class=\"ansiyellow\">,</span> n_boot<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/seaborn/categorical.py</span> in <span class=\"ansicyan\">establish_variables</span><span class=\"ansiblue\">(self, x, y, hue, data, orient, order, hue_order, units)</span>\n",
       "<span class=\"ansigreen\">    197</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    198</span>                 <span class=\"ansired\"># Get the order on the categorical axis</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 199</span><span class=\"ansiyellow\">                 </span>group_names <span class=\"ansiyellow\">=</span> categorical_order<span class=\"ansiyellow\">(</span>groups<span class=\"ansiyellow\">,</span> order<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    200</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    201</span>                 <span class=\"ansired\"># Group the numeric data</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/seaborn/utils.py</span> in <span class=\"ansicyan\">categorical_order</span><span class=\"ansiblue\">(values, order)</span>\n",
       "<span class=\"ansigreen\">    531</span>                 <span class=\"ansigreen\">except</span> <span class=\"ansiyellow\">(</span>ValueError<span class=\"ansiyellow\">,</span> TypeError<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    532</span>                     order <span class=\"ansiyellow\">=</span> order<span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 533</span><span class=\"ansiyellow\">         </span>order <span class=\"ansiyellow\">=</span> filter<span class=\"ansiyellow\">(</span>pd<span class=\"ansiyellow\">.</span>notnull<span class=\"ansiyellow\">,</span> order<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    534</span>     <span class=\"ansigreen\">return</span> list<span class=\"ansiyellow\">(</span>order<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    535</span> <span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/column.py</span> in <span class=\"ansicyan\">__iter__</span><span class=\"ansiblue\">(self)</span>\n",
       "<span class=\"ansigreen\">    342</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    343</span>     <span class=\"ansigreen\">def</span> __iter__<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 344</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">raise</span> TypeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Column is not iterable&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    345</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    346</span>     <span class=\"ansired\"># string methods</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansired\">TypeError</span>: Column is not iterable</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare the 2 labels\n",
    "import seaborn as sns\n",
    "sns.countplot(df1['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-----+--------------------+--------------------+\n",
       "Label|              Review|        review_words|\n",
       "+-----+--------------------+--------------------+\n",
       "    2|Stuning even for ...|[stuning, even, f...|\n",
       "    2|The best soundtra...|[the, best, sound...|\n",
       "+-----+--------------------+--------------------+\n",
       "only showing top 2 rows\n",
       "\n",
       "+-----+--------------------+--------------------+--------------------+\n",
       "Label|              Review|        review_words|            filtered|\n",
       "+-----+--------------------+--------------------+--------------------+\n",
       "    2|Stuning even for ...|[stuning, even, f...|[stuning, even, n...|\n",
       "    2|The best soundtra...|[the, best, sound...|[best, soundtrack...|\n",
       "+-----+--------------------+--------------------+--------------------+\n",
       "only showing top 2 rows\n",
       "\n",
       "+-----+--------------------+--------------------+--------------------+--------------------+\n",
       "Label|              Review|        review_words|            filtered|                  TF|\n",
       "+-----+--------------------+--------------------+--------------------+--------------------+\n",
       "    2|Stuning even for ...|[stuning, even, f...|[stuning, even, n...|(262144,[9129,133...|\n",
       "    2|The best soundtra...|[the, best, sound...|[best, soundtrack...|(262144,[2991,132...|\n",
       "+-----+--------------------+--------------------+--------------------+--------------------+\n",
       "only showing top 2 rows\n",
       "\n",
       "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
       "Label|              Review|        review_words|            filtered|                  TF|            features|\n",
       "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
       "    2|Stuning even for ...|[stuning, even, f...|[stuning, even, n...|(262144,[9129,133...|(262144,[9129,133...|\n",
       "    2|The best soundtra...|[the, best, sound...|[best, soundtrack...|(262144,[2991,132...|(262144,[2991,132...|\n",
       "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
       "only showing top 2 rows\n",
       "\n",
       "Row(TF=SparseVector(262144, {9129: 1.0, 13381: 1.0, 20069: 1.0, 26471: 1.0, 32826: 1.0, 32957: 1.0, 41006: 1.0, 41704: 1.0, 50134: 1.0, 62790: 1.0, 68203: 1.0, 72709: 1.0, 87566: 2.0, 93398: 1.0, 96316: 1.0, 98065: 1.0, 102573: 1.0, 112623: 1.0, 114686: 1.0, 138193: 1.0, 138895: 2.0, 145080: 1.0, 149784: 1.0, 152471: 1.0, 166027: 1.0, 170317: 1.0, 170688: 1.0, 174966: 2.0, 178465: 1.0, 186925: 1.0, 188123: 1.0, 193400: 1.0, 203802: 1.0, 207954: 1.0, 209326: 1.0, 217825: 2.0, 235131: 1.0, 237887: 1.0}), label=&apos;2&apos;)\n",
       "\n",
       " Row(features=SparseVector(262144, {9129: 3.7191, 13381: 3.3395, 20069: 7.8474, 26471: 8.5698, 32826: 10.2965, 32957: 4.4766, 41006: 9.2382, 41704: 4.8905, 50134: 3.9394, 62790: 5.2688, 68203: 8.1933, 72709: 4.5903, 87566: 14.3915, 93398: 6.7889, 96316: 6.13, 98065: 8.531, 102573: 10.4227, 112623: 7.089, 114686: 2.8651, 138193: 3.2664, 138895: 7.455, 145080: 8.1405, 149784: 11.8006, 152471: 7.3906, 166027: 2.5201, 170317: 11.4406, 170688: 4.3974, 174966: 4.2566, 178465: 4.8931, 186925: 2.4811, 188123: 5.3229, 193400: 8.1915, 203802: 2.8574, 207954: 6.1171, 209326: 6.6664, 217825: 8.6082, 235131: 9.3102, 237887: 7.7079}), label=&apos;2&apos;)\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Tokenize the review \n",
    "tokenizer = Tokenizer(inputCol=\"Review\", outputCol=\"review_words\")\n",
    "wordsDF = tokenizer.transform(df1)\n",
    "wordsDF.show(2)\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"review_words\", outputCol=\"filtered\")\n",
    "wordsDF2 = remover.transform(wordsDF)\n",
    "wordsDF2.show(2)\n",
    "\n",
    "# Convert to TF words vector\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"TF\")\n",
    "wordsDF3 = hashingTF.transform(wordsDF2)\n",
    "wordsDF3.show(2)\n",
    "\n",
    "# Convert to IDF words vector, ensure to name the features as 'features'\n",
    "idf = IDF(inputCol=\"TF\", outputCol=\"features\")\n",
    "idfModel = idf.fit(wordsDF3)\n",
    "wordsDF4 = idfModel.transform(wordsDF3)\n",
    "wordsDF4.show(2)\n",
    "\n",
    "# HashingTF in SparkML can't normalize term frequency with the total number of words in each document\n",
    "for features_label in wordsDF3.select(\"TF\", \"label\").take(1):\n",
    "    print(features_label)\n",
    "\n",
    "# IDF features\n",
    "for features_label in wordsDF4.select(\"features\", \"label\").take(1):\n",
    "    print(\"\\n\",features_label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansired\">IllegalArgumentException</span>                  Traceback (most recent call last)\n",
       "<span class=\"ansigreen\">&lt;command-3451440845433279&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n",
       "<span class=\"ansigreen\">     25</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     26</span> <span class=\"ansired\"># Run cross-validation, and choose the best set of parameters.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">---&gt; 27</span><span class=\"ansiyellow\"> </span>cvModel <span class=\"ansiyellow\">=</span> crossval<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>training<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     28</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     29</span> <span class=\"ansired\"># Make predictions on test documents. cvModel uses the best model found (lrModel).</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansicyan\">fit</span><span class=\"ansiblue\">(self, dataset, params)</span>\n",
       "<span class=\"ansigreen\">    130</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    131</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 132</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    133</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    134</span>             raise ValueError(&quot;Params must be either a param map or a list/tuple of param maps, &quot;\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/tuning.py</span> in <span class=\"ansicyan\">_fit</span><span class=\"ansiblue\">(self, dataset)</span>\n",
       "<span class=\"ansigreen\">    302</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    303</span>             tasks <span class=\"ansiyellow\">=</span> _parallelFitTasks<span class=\"ansiyellow\">(</span>est<span class=\"ansiyellow\">,</span> train<span class=\"ansiyellow\">,</span> eva<span class=\"ansiyellow\">,</span> validation<span class=\"ansiyellow\">,</span> epm<span class=\"ansiyellow\">,</span> collectSubModelsParam<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 304</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">for</span> j<span class=\"ansiyellow\">,</span> metric<span class=\"ansiyellow\">,</span> subModel <span class=\"ansigreen\">in</span> pool<span class=\"ansiyellow\">.</span>imap_unordered<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> f<span class=\"ansiyellow\">:</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> tasks<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    305</span>                 metrics<span class=\"ansiyellow\">[</span>j<span class=\"ansiyellow\">]</span> <span class=\"ansiyellow\">+=</span> <span class=\"ansiyellow\">(</span>metric <span class=\"ansiyellow\">/</span> nFolds<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    306</span>                 <span class=\"ansigreen\">if</span> collectSubModelsParam<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/usr/lib/python3.5/multiprocessing/pool.py</span> in <span class=\"ansicyan\">next</span><span class=\"ansiblue\">(self, timeout)</span>\n",
       "<span class=\"ansigreen\">    693</span>         <span class=\"ansigreen\">if</span> success<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    694</span>             <span class=\"ansigreen\">return</span> value<span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 695</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">raise</span> value<span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    696</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    697</span>     __next__ <span class=\"ansiyellow\">=</span> next                    <span class=\"ansired\"># XXX</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/usr/lib/python3.5/multiprocessing/pool.py</span> in <span class=\"ansicyan\">worker</span><span class=\"ansiblue\">(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)</span>\n",
       "<span class=\"ansigreen\">    117</span>         job<span class=\"ansiyellow\">,</span> i<span class=\"ansiyellow\">,</span> func<span class=\"ansiyellow\">,</span> args<span class=\"ansiyellow\">,</span> kwds <span class=\"ansiyellow\">=</span> task<span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    118</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 119</span><span class=\"ansiyellow\">             </span>result <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">(</span><span class=\"ansigreen\">True</span><span class=\"ansiyellow\">,</span> func<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>args<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kwds<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    120</span>         <span class=\"ansigreen\">except</span> Exception <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    121</span>             <span class=\"ansigreen\">if</span> wrap_exception<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/tuning.py</span> in <span class=\"ansicyan\">&lt;lambda&gt;</span><span class=\"ansiblue\">(f)</span>\n",
       "<span class=\"ansigreen\">    302</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    303</span>             tasks <span class=\"ansiyellow\">=</span> _parallelFitTasks<span class=\"ansiyellow\">(</span>est<span class=\"ansiyellow\">,</span> train<span class=\"ansiyellow\">,</span> eva<span class=\"ansiyellow\">,</span> validation<span class=\"ansiyellow\">,</span> epm<span class=\"ansiyellow\">,</span> collectSubModelsParam<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 304</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">for</span> j<span class=\"ansiyellow\">,</span> metric<span class=\"ansiyellow\">,</span> subModel <span class=\"ansigreen\">in</span> pool<span class=\"ansiyellow\">.</span>imap_unordered<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> f<span class=\"ansiyellow\">:</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> tasks<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    305</span>                 metrics<span class=\"ansiyellow\">[</span>j<span class=\"ansiyellow\">]</span> <span class=\"ansiyellow\">+=</span> <span class=\"ansiyellow\">(</span>metric <span class=\"ansiyellow\">/</span> nFolds<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    306</span>                 <span class=\"ansigreen\">if</span> collectSubModelsParam<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/tuning.py</span> in <span class=\"ansicyan\">singleTask</span><span class=\"ansiblue\">()</span>\n",
       "<span class=\"ansigreen\">     50</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     51</span>     <span class=\"ansigreen\">def</span> singleTask<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">---&gt; 52</span><span class=\"ansiyellow\">         </span>index<span class=\"ansiyellow\">,</span> model <span class=\"ansiyellow\">=</span> next<span class=\"ansiyellow\">(</span>modelIter<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     53</span>         metric <span class=\"ansiyellow\">=</span> eva<span class=\"ansiyellow\">.</span>evaluate<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">.</span>transform<span class=\"ansiyellow\">(</span>validation<span class=\"ansiyellow\">,</span> epm<span class=\"ansiyellow\">[</span>index<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     54</span>         <span class=\"ansigreen\">return</span> index<span class=\"ansiyellow\">,</span> metric<span class=\"ansiyellow\">,</span> model <span class=\"ansigreen\">if</span> collectSubModel <span class=\"ansigreen\">else</span> <span class=\"ansigreen\">None</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansicyan\">__next__</span><span class=\"ansiblue\">(self)</span>\n",
       "<span class=\"ansigreen\">     60</span>                 <span class=\"ansigreen\">raise</span> StopIteration<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;No models remaining.&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     61</span>             self<span class=\"ansiyellow\">.</span>counter <span class=\"ansiyellow\">+=</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">---&gt; 62</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> index<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>fitSingleModel<span class=\"ansiyellow\">(</span>index<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     63</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     64</span>     <span class=\"ansigreen\">def</span> next<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansicyan\">fitSingleModel</span><span class=\"ansiblue\">(index)</span>\n",
       "<span class=\"ansigreen\">    104</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    105</span>         <span class=\"ansigreen\">def</span> fitSingleModel<span class=\"ansiyellow\">(</span>index<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 106</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> estimator<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">,</span> paramMaps<span class=\"ansiyellow\">[</span>index<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    107</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    108</span>         <span class=\"ansigreen\">return</span> _FitMultipleIterator<span class=\"ansiyellow\">(</span>fitSingleModel<span class=\"ansiyellow\">,</span> len<span class=\"ansiyellow\">(</span>paramMaps<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansicyan\">fit</span><span class=\"ansiblue\">(self, dataset, params)</span>\n",
       "<span class=\"ansigreen\">    128</span>         <span class=\"ansigreen\">elif</span> isinstance<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">,</span> dict<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    129</span>             <span class=\"ansigreen\">if</span> params<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 130</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    131</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    132</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/pipeline.py</span> in <span class=\"ansicyan\">_fit</span><span class=\"ansiblue\">(self, dataset)</span>\n",
       "<span class=\"ansigreen\">    107</span>                     dataset <span class=\"ansiyellow\">=</span> stage<span class=\"ansiyellow\">.</span>transform<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    108</span>                 <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span>  <span class=\"ansired\"># must be an Estimator</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 109</span><span class=\"ansiyellow\">                     </span>model <span class=\"ansiyellow\">=</span> stage<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    110</span>                     transformers<span class=\"ansiyellow\">.</span>append<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    111</span>                     <span class=\"ansigreen\">if</span> i <span class=\"ansiyellow\">&lt;</span> indexOfLastEstimator<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansicyan\">fit</span><span class=\"ansiblue\">(self, dataset, params)</span>\n",
       "<span class=\"ansigreen\">    130</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    131</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 132</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    133</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    134</span>             raise ValueError(&quot;Params must be either a param map or a list/tuple of param maps, &quot;\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansicyan\">_fit</span><span class=\"ansiblue\">(self, dataset)</span>\n",
       "<span class=\"ansigreen\">    293</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    294</span>     <span class=\"ansigreen\">def</span> _fit<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 295</span><span class=\"ansiyellow\">         </span>java_model <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_fit_java<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    296</span>         model <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_create_model<span class=\"ansiyellow\">(</span>java_model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    297</span>         <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_copyValues<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansicyan\">_fit_java</span><span class=\"ansiblue\">(self, dataset)</span>\n",
       "<span class=\"ansigreen\">    290</span>         &quot;&quot;&quot;\n",
       "<span class=\"ansigreen\">    291</span>         self<span class=\"ansiyellow\">.</span>_transfer_params_to_java<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">--&gt; 292</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_java_obj<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    293</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">    294</span>     <span class=\"ansigreen\">def</span> _fit<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n",
       "<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n",
       "<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n",
       "</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n",
       "<span class=\"ansigreen\">     77</span>                 <span class=\"ansigreen\">raise</span> QueryExecutionException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     78</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;java.lang.IllegalArgumentException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">---&gt; 79</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> IllegalArgumentException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     80</span>             <span class=\"ansigreen\">raise</span><span class=\"ansiyellow\"></span>\n",
       "<span class=\"ansigreen\">     81</span>     <span class=\"ansigreen\">return</span> deco<span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansired\">IllegalArgumentException</span>: &apos;Field &quot;label&quot; does not exist.\\nAvailable fields: Label, Review, CrossValidator_a62d886b0546_rand, review_words, filtered, TF, features&apos;</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Split data into training and testing set \n",
    "(training, test) = df1.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a logistic regression instance\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "# Use a pipeline to chain all transformers and estimators\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idfModel, lr])\n",
    "\n",
    "# We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "# This will allow us to jointly choose parameters for all Pipeline stages.\n",
    "# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 50]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3) \n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)\n",
    "selected = prediction.select(\"Review\", \"Label\", \"probability\", \"prediction\").take(5)\n",
    "for row in selected:\n",
    "    print(row)\n",
    "\n",
    "# Evaluate result with ROC\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Label\", metricName=\"areaUnderROC\")\n",
    "ROC = evaluator.evaluate(prediction)\n",
    "ROC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "Amazon Review Sentiment Analysis- PySpark",
  "notebookId": 3840250711670689
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
